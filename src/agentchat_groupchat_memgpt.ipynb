{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_groupchat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Group Chat\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "This notebook is modified based on https://github.com/microsoft/FLAML/blob/4ea686af5c3e8ff24d9076a7a626c8b28ab5b1d7/notebook/autogen_multiagent_roleplay_chat.ipynb\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "# %pip install pyautogen~=0.2.0b4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import os\n",
    "\n",
    "# config_list_gpt4 = autogen.config_list_from_json(\n",
    "#     \"OAI_CONFIG_LIST\",\n",
    "#     filter_dict={\n",
    "#         \"model\": [\"gpt-4\", \"gpt-4-0314\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
    "#     },\n",
    "# )\n",
    "\n",
    "config_list_gpt4 = [\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "        # \"api_key\": str(os.environ[\"OPENAI_API_KEY\"]),\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4-32k\",\n",
    "        \"api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "# config_list_gpt35 = autogen.config_list_from_json(\n",
    "#     \"OAI_CONFIG_LIST\",\n",
    "#     filter_dict={\n",
    "#         \"model\": {\n",
    "#             \"gpt-3.5-turbo\",\n",
    "#             \"gpt-3.5-turbo-16k\",\n",
    "#             \"gpt-3.5-turbo-0301\",\n",
    "#             \"chatgpt-35-turbo-0301\",\n",
    "#             \"gpt-35-turbo-v0301\",\n",
    "#         },\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well). Only the gpt-4 models are kept in the list based on the filter condition.\n",
    "\n",
    "The config list looks like the following:\n",
    "```python\n",
    "config_list = [\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your OpenAI API key here>',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "    {\n",
    "        'model': 'gpt-4-32k',\n",
    "        'api_key': '<your Azure OpenAI API key here>',\n",
    "        'base_url': '<your Azure OpenAI API base here>',\n",
    "        'api_type': 'azure',\n",
    "        'api_version': '2023-06-01-preview',\n",
    "    },\n",
    "]\n",
    "```\n",
    "\n",
    "You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Marketing_Expert = \"\"\"\n",
    "Name: Alex the Marketing Expert\n",
    "Age: 32\n",
    "Background: Holds a Master's degree in Marketing and has a passion for cycling. Alex has previously worked with several sports brands and has a deep understanding of the biking community.\n",
    "Personality Traits: Creative, data-driven, and trend-savvy. Excels in digital marketing strategies.\n",
    "Goals: To increase brand visibility and engage more with the biking community through innovative marketing campaigns.\n",
    "Challenges: Keeping up with rapidly changing marketing trends and consumer preferences.\n",
    "Digital Marketing: Expert in SEO, social media advertising, and email marketing campaigns specifically tailored for the sports industry.\n",
    "Brand Development: Skilled in developing and maintaining a strong brand identity that resonates with the biking community.\n",
    "Market Research: Proficient in conducting market analysis to identify new trends and customer needs in the biking market.\n",
    "Content Creation: Talented in creating engaging content (blogs, videos, social media posts) to drive brand awareness and customer engagement.\n",
    "\"\"\"\n",
    "Sales_Expert = \"\"\"\n",
    "Name: Emma the Sales Expert\n",
    "Age: 28\n",
    "Background: Emma has a Bachelor's degree in Business Administration and has been working in sales for 5 years, specializing in sports equipment. She's known for her exceptional customer service skills and product knowledge.\n",
    "Personality Traits: Outgoing, persuasive, and empathetic. Great at building relationships and understanding customer needs.\n",
    "Goals: To consistently exceed sales targets and develop strong, long-lasting relationships with key clients.\n",
    "Customer Relationship Management: Excel at building and maintaining strong relationships with clients, ensuring long-term customer loyalty.\n",
    "Product Knowledge: In-depth understanding of biking products and the ability to articulate product benefits effectively to customers.\n",
    "Sales Strategy: Proficient in developing and implementing effective sales strategies to target various customer segments in the biking market.\n",
    "Negotiation Skills: Strong negotiation skills to close deals and secure new business opportunities.\n",
    "\"\"\"\n",
    "Manager = \"\"\"\n",
    "Name: Michael the Manager\n",
    "Age: 40\n",
    "Background: With an MBA and over 15 years of experience in management roles, Michael has a solid track record in leading teams and driving company growth. He's particularly adept at strategic planning and operations management.\n",
    "Personality Traits: Leadership-oriented, analytical, and decisive. Excellent at problem-solving and team management.\n",
    "Goals: To streamline operations for efficiency, foster a positive work culture, and drive the company towards its strategic goals.\n",
    "Strategic Planning: Excellent at setting strategic goals for the company and developing plans to achieve these goals.\n",
    "Team Management: Skilled in managing diverse teams, fostering a collaborative and productive work environment.\n",
    "Financial Acumen: Strong understanding of budgeting, financial planning, and resource allocation to maximize efficiency and profitability.\n",
    "Operational Oversight: Proficient in overseeing daily operations, ensuring processes are streamlined and goals are met.\n",
    "\"\"\"\n",
    "Business_Overview = \"\"\"\n",
    "The market for sports articles for bikers is dynamic and multifaceted, catering to a wide range of customers from casual riders to professional athletes. It encompasses various segments including road biking, mountain biking, BMX, and leisure biking. The demand is driven by a growing interest in outdoor activities, fitness, and eco-friendly modes of transportation.\n",
    "Key Segments:\n",
    "Road Biking: This segment includes high-performance bikes and gear for speed and endurance, appealing to serious athletes and fitness enthusiasts. The market is dominated by a few major brands such as Trek, Cannondale, and Specialized.\n",
    "Internal Weakness: Limited Online Presence and Digital Marketing Expertise.\n",
    "Your company currently has a minimal online presence, with a basic website and limited activity on social media platforms. The in-house team lacks expertise in digital marketing, SEO, and e-commerce strategies. This deficiency results in reduced online visibility and a lack of engagement with potential customers, especially those who predominantly shop and seek information online.\n",
    "Market Opportunity: Growing Demand for E-Bikes.\n",
    "\"\"\"\n",
    "email = \"\"\"\n",
    "Subject: Strategy Meeting Invitation: Capitalizing on E-Bike Market Opportunity\n",
    "\n",
    "Body:\n",
    "\n",
    "Dear Alex, Emma, and Michael,\n",
    "\n",
    "I hope this email finds you well. As we navigate through an increasingly competitive market, it is essential that we continually align our strategies with emerging opportunities and internal capabilities. To this end, I would like to invite you to a strategic meeting to discuss a significant opportunity in the e-bike market and address our current internal challenges that are im\n",
    "\"\"\"\n",
    "meeting_opener = \"\"\"\n",
    "\"Good morning everyone,\n",
    "\n",
    "Thank you for joining this crucial meeting today. I'm excited to discuss an opportunity that has the potential to significantly impact our market positioning and overall growth.\n",
    "\n",
    "Firstly, let's talk about the opportunity at hand. We're witnessing a substantial shift in consumer preferences towards e-bikes, especially among urban commuters. This trend isn't just a fleeting one; it's driven by increasing environmental awareness, the need for efficient commuting options, an aging population, and a growing interest in fitness. In fact, the global e-bike market is expected to grow at a CAGR of 9.01% from 2021 to 2028, reaching a value of $38.6 billion by 2028.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\"config_list\": config_list_gpt4}\n",
    "marketing = autogen.AssistantAgent(\n",
    "    name=\"Alex_the_Marketing_Expert\",\n",
    "    system_message=Marketing_Expert,\n",
    "    # human_input_mode=\"TERMINATE\",\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "sales = autogen.UserProxyAgent(\n",
    "    name=\"Emma_the_Sales_Expert\",\n",
    "    # human_input_mode=\"NEVER\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    system_message=Sales_Expert,\n",
    "    llm_config=llm_config,\n",
    ")\n",
    "# manager = autogen.AssistantAgent(\n",
    "#     name=\"Michael_the_Manager\",\n",
    "#     system_message=Manager,\n",
    "#     # human_input_mode=\"TERMINATE\",\n",
    "#     llm_config=llm_config,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_endpoint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m config_list_memgpt \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39m# \"model\": \"gpt-4-1106-preview\",  # gpt-4-turbo (https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     },\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m llm_config_memgpt \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mconfig_list\u001b[39m\u001b[39m\"\u001b[39m: config_list_memgpt}\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m manager \u001b[39m=\u001b[39m create_memgpt_autogen_agent_from_config(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mMichael_the_Mannager\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     llm_config\u001b[39m=\u001b[39mllm_config_memgpt,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     nonmemgpt_llm_config\u001b[39m=\u001b[39mllm_config,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     system_message\u001b[39m=\u001b[39mManager,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     interface_kwargs\u001b[39m=\u001b[39minterface_kwargs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     human_input_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNEVER\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m# Set a default auto-reply message here (non-empty auto-reply is required for LM Studio)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/panoevj/my-repos/Tiny_Agents/src/agentchat_groupchat_memgpt.ipynb#X15sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/automemgpt/lib/python3.11/site-packages/memgpt/autogen/memgpt_agent.py:61\u001b[0m, in \u001b[0;36mcreate_memgpt_autogen_agent_from_config\u001b[0;34m(name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, nonmemgpt_llm_config, default_auto_reply, interface_kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     user_desc \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWork by yourself, the user won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt reply. Elaborate as much as possible.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[39m# Create an AgentConfig option from the inputs\u001b[39;00m\n\u001b[1;32m     53\u001b[0m agent_config \u001b[39m=\u001b[39m AgentConfig(\n\u001b[1;32m     54\u001b[0m     name\u001b[39m=\u001b[39mname,\n\u001b[1;32m     55\u001b[0m     persona\u001b[39m=\u001b[39mpersona_desc,\n\u001b[1;32m     56\u001b[0m     human\u001b[39m=\u001b[39muser_desc,\n\u001b[1;32m     57\u001b[0m     preset\u001b[39m=\u001b[39mllm_config[\u001b[39m\"\u001b[39m\u001b[39mpreset\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     58\u001b[0m     model\u001b[39m=\u001b[39mllm_config[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     59\u001b[0m     model_wrapper\u001b[39m=\u001b[39mllm_config[\u001b[39m\"\u001b[39m\u001b[39mmodel_wrapper\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     60\u001b[0m     model_endpoint_type\u001b[39m=\u001b[39mllm_config[\u001b[39m\"\u001b[39m\u001b[39mmodel_endpoint_type\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m---> 61\u001b[0m     model_endpoint\u001b[39m=\u001b[39mllm_config[\u001b[39m\"\u001b[39m\u001b[39mmodel_endpoint\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     62\u001b[0m     context_window\u001b[39m=\u001b[39mllm_config[\u001b[39m\"\u001b[39m\u001b[39mcontext_window\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     63\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m function_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m code_execution_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_endpoint'"
     ]
    }
   ],
   "source": [
    "from memgpt.autogen.memgpt_agent import (\n",
    "    create_autogen_memgpt_agent,\n",
    "    create_memgpt_autogen_agent_from_config,\n",
    ")\n",
    "from memgpt.presets.presets import DEFAULT_PRESET\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "interface_kwargs = {\n",
    "    \"debug\": DEBUG,\n",
    "    \"show_inner_thoughts\": DEBUG,\n",
    "    \"show_function_outputs\": DEBUG,\n",
    "}\n",
    "\n",
    "config_list_memgpt = [\n",
    "    {\n",
    "        # \"model\": \"gpt-4-1106-preview\",  # gpt-4-turbo (https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\n",
    "        \"model\": \"gpt-4-1106-preview\",  # gpt-4-turbo (https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo)\n",
    "        \"preset\": DEFAULT_PRESET,\n",
    "        \"model_wrapper\": None,\n",
    "        \"api_type\": \"open_ai\",\n",
    "        \"model_endpoint_type\": \"openai\",\n",
    "        \"model_endpoint\": \"https://v1\",\n",
    "        \"context_window\": 128000,  # gpt-4-turbo\n",
    "    },\n",
    "]\n",
    "\n",
    "llm_config_memgpt = {\"config_list\": config_list_memgpt}\n",
    "\n",
    "manager = create_memgpt_autogen_agent_from_config(\n",
    "    \"Michael_the_Mannager\",\n",
    "    llm_config=llm_config_memgpt,\n",
    "    nonmemgpt_llm_config=llm_config,\n",
    "    system_message=Manager,\n",
    "    interface_kwargs=interface_kwargs,\n",
    "    human_input_mode=\"NEVER\",  # Set a default auto-reply message here (non-empty auto-reply is required for LM Studio)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[marketing, sales, manager], messages=[], max_round=5\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.initiate_chat(\n",
    "    manager,\n",
    "    message=Business_Overview + email + meeting_opener,\n",
    ")\n",
    "# type exit to terminate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
